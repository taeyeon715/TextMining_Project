{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32925911",
   "metadata": {},
   "source": [
    "# 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "497235d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류된 데이터가 성공적으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# TextMining_수만휘_수시게시판_통합.csv에서 양식별로 column 찢기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('TextMining_수만휘_수시게시판_통합.csv',encoding='utf-8-sig')\n",
    "df['content'] = df['content'].astype(str)\n",
    "df['content'] = df['content'].str.strip()\n",
    "\n",
    "# 데이터프레임 생성\n",
    "new_df = pd.DataFrame(df, columns=df.columns)\n",
    "\n",
    "# 새로운 열을 추가하여 데이터를 분류\n",
    "new_columns = ['1. 입시결과 요약', '2. 출신고교 종류', '3. 내신/수능점수', '4. 스펙', '5. 후배들에게 전하고 싶은 말', '6. 수험 수기']\n",
    "new_df = pd.DataFrame(columns=new_columns)\n",
    "\n",
    "current_col_index = 0  # 현재 열 인덱스\n",
    "row_data = [''] * 6  # 초기화된 분류 데이터 리스트\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    content = str(row['content']).replace('\\n', ' ')  # 개행 문자 제거\n",
    "    \n",
    "    # 개행 문자 제거\n",
    "    content = re.sub(r'[^\\w\\s\\.\\-/.~]', '', content)\n",
    "    \n",
    "    sentences = re.split(r'(?<=\\d)\\.(?=\\s)', content)\n",
    "    \n",
    "    row_data = [''] * 6  # 각 행마다 row_data를 새로 초기화\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # 문장의 맨 끝에 있는 1개의 숫자 제거\n",
    "        sentence = re.sub(r'\\d$', '', sentence)\n",
    "        \n",
    "        if '입시결과' in sentence:\n",
    "            current_col_index = 0  # '1'이 나왔을 때 현재 열 인덱스를 0으로 설정\n",
    "            row_data[current_col_index] = sentence.replace('입시결과 요약합격 또는 불합격한 대학명/ 학과 / 전형', '')  # 1. 열에 해당하는 데이터에 문장 추가\n",
    "        elif '출신고교' in sentence:\n",
    "            current_col_index = 1  # '2'가 나왔을 때 현재 열 인덱스를 1로 설정\n",
    "            row_data[current_col_index] = sentence.replace('출신고교의 종류 / 성별성별이 영향을 주는 전형이 아니면 적지 않으셔도 됩니다', '')  # 2. 열에 해당하는 데이터에 문장 추가\n",
    "        elif '내신/수능' in sentence:\n",
    "            current_col_index = 2  # '3'이 나왔을 때 현재 열 인덱스를 2로 설정\n",
    "            row_data[current_col_index] = sentence.replace('내신/수능 점수', '')  # 3. 열에 해당하는 데이터에 문장 추가\n",
    "        elif '스펙' in sentence:\n",
    "            current_col_index = 3  # '4'가 나왔을 때 현재 열 인덱스를 3로 설정\n",
    "            row_data[current_col_index] = sentence.replace('스펙', '')  # 4. 열에 해당하는 데이터에 문장 추가\n",
    "        elif '후배들에게' in sentence:\n",
    "            current_col_index = 4  # '5'가 나왔을 때 현재 열 인덱스를 4로 설정\n",
    "            row_data[current_col_index] = sentence.replace('후배들에게 전하고 싶은 말', '')  # 5. 열에 해당하는 데이터에 문장 추가\n",
    "        elif '수험 수기' in sentence:\n",
    "            current_col_index = 5  # '6'이 나왔을 때 현재 열 인덱스를 5로 설정\n",
    "            row_data[current_col_index] = sentence.replace('수험 수기작성하시고 픈 분만 작성하셔도 됩니다.', '')  # 6. 열에 해당하는 데이터에 문장 추가\n",
    "        else:\n",
    "            row_data[current_col_index] += sentence  # 현재 열에 해당하는 데이터에 문장 추가\n",
    "    \n",
    "    new_df.loc[index] = row_data\n",
    "\n",
    "# 기존 DataFrame에 열 추가\n",
    "df[new_columns] = new_df[new_columns]\n",
    "\n",
    "# '1. 입시결과'나 '2. 스펙' 열 등 데이터가 없는 행을 삭제하는 코드\n",
    "df = df.drop(df[(df['1. 입시결과 요약'] == '') | (df['1. 입시결과 요약'] == ' ') | (df['2. 출신고교 종류'] == '') | (df['2. 출신고교 종류'] == ' ') | (df['3. 내신/수능점수'] == '') | (df['3. 내신/수능점수'] == ' ') | (df['4. 스펙'] == '') | (df['4. 스펙'] == ' ') | (df['5. 후배들에게 전하고 싶은 말'] == '') | (df['5. 후배들에게 전하고 싶은 말'] == ' ')].index)\n",
    "df.drop('6. 수험 수기', axis=1, inplace=True)\n",
    "df.to_csv('수만휘_전처리.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print('분류된 데이터가 성공적으로 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16dd26fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추출이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 엑셀 파일 경로\n",
    "file_path = '수만휘_전처리.csv'\n",
    "\n",
    "# 엑셀 파일 읽기\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 9열에만 전처리를 적용할 경우\n",
    "target_column_school = 9\n",
    "# 10열에만 전처리를 적용할 경우\n",
    "target_column_score = 10\n",
    "\n",
    "# 전처리를 위한 함수 정의 10열\n",
    "def preprocess_score(value):\n",
    "    if isinstance(value, str):\n",
    "        # \"평균\", \"총\", \"전과목\", \"최종\" 처리\n",
    "        words = value.split()\n",
    "        result1 = []\n",
    "        for i, word in enumerate(words):\n",
    "            if word in ['평균', '총', '전과목', '최종', '전교과', '내신', '총내신', '총합']:\n",
    "                if i+1 < len(words):\n",
    "                    number = re.findall(r'\\d+\\.\\d+', words[i+1])\n",
    "                    result1.extend(number)\n",
    "\n",
    "        # 숫자5개 연속 처리\n",
    "        for word in words:\n",
    "            if len(word) == 5 and word.isdigit():\n",
    "                result1.append(word)\n",
    "\n",
    "        return ', '.join(result1) if result1 else ''\n",
    "    return ''\n",
    "\n",
    "# 전처리를 위한 함수 정의 9열\n",
    "def preprocess_school(value):\n",
    "    if isinstance(value, str):\n",
    "        words = value.split()  # 문장을 단어로 분리\n",
    "        result2 = []\n",
    "        for word in words:\n",
    "            if any(keyword in word for keyword in ['일반', '과학', '특성화', '자사', '외','외국어']):\n",
    "                if '일반' in word:\n",
    "                    word = '일반고'\n",
    "                elif '과학' in word:\n",
    "                    word = '과학고'\n",
    "                elif '특성화' in word:\n",
    "                    word = '특성화고'\n",
    "                elif '자사' in word:\n",
    "                    word = '자사고'\n",
    "                elif '외' in word or '외국어' in word:\n",
    "                    word = '외고'\n",
    "                result2.append(word)\n",
    "        if result2:\n",
    "            return ', '.join(result2)\n",
    "    return ''\n",
    "\n",
    "\n",
    "column_name1 = df.columns[target_column_score]\n",
    "column_name2 = df.columns[target_column_school]\n",
    "\n",
    "# 전처리된 값을 저장할 새로운 열 이름\n",
    "new_column_name1 = \"preprocessed_score\"\n",
    "new_column_name2 = \"preprocessed_school\"\n",
    "\n",
    "# 새로운 열 생성 및 전처리된 값 저장\n",
    "#df[new_column_name1] = df[column_name1].apply(preprocess_score)\n",
    "#df[new_column_name2] = df[column_name2].apply(preprocess_school)\n",
    "df['3. 내신/수능점수'] = df['3. 내신/수능점수'].apply(preprocess_score)\n",
    "df['2. 출신고교 종류'] = df['2. 출신고교 종류'].apply(preprocess_school)\n",
    "\n",
    "# 새로운 CSV 파일로 저장\n",
    "df.to_csv('수만휘_전처리_내신&학교.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"추출이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2e6e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수능 점수 제거 = 내신 점수만 남김\n",
    "# 이후 평균 내기 위해서. 그리고 애초에 여기는 \"수시 합격 수기 게시판\"이라 내신 점수만 있어도 된다고 판단.\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "data = pd.read_csv('수만휘_전처리_내신&학교.csv')\n",
    "\n",
    "# 정규식 패턴으로 3개 이상 연속된 숫자 형태의 값 찾기\n",
    "pattern = r'\\d{3,}'\n",
    "data['3. 내신/수능점수'] = data['3. 내신/수능점수'].apply(lambda x: re.sub(pattern, '', str(x).replace(',', '')) if pd.notnull(x) else np.nan)\n",
    "\n",
    "# 결과를 새로운 CSV 파일로 저장하기\n",
    "data.to_csv('수만휘_전처리_내신&학교.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59652f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 파일이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "csv_file = \"수만휘_전처리_내신&학교.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "def extract_string_with_words(sentence, conditions):\n",
    "    matches = []\n",
    "    for condition in conditions:\n",
    "        word1 = condition[\"word1\"]\n",
    "        word2 = condition[\"word2\"]\n",
    "        pattern = r\"\\b\" + word1 + r\"\\s*(?:\\d+\\s*)?\\w*\\s*\" + word2 + r\"\\b\"  # 수정된 정규표현식\n",
    "        match = re.search(pattern, sentence, flags=re.IGNORECASE)  # 대소문자 무시하도록 flags 추가\n",
    "        if match:\n",
    "            extracted_string = match.group().strip()  # 매치된 문자열에서 앞뒤 공백 제거\n",
    "            matches.append(extracted_string)\n",
    "    return matches\n",
    "\n",
    "# 추출할 단어 설정\n",
    "conditions = [\n",
    "    {\"word1\": \"생기부\", \"word2\": \"장\"},\n",
    "    {\"word1\": \"독서\", \"word2\": \"권\"},\n",
    "    {\"word1\": \"봉사활동\", \"word2\": \"시간\"},\n",
    "    {\"word1\": \"봉사\", \"word2\": \"시간\"},\n",
    "    {\"word1\": \"상장\", \"word2\": \"개\"},\n",
    "    {\"word1\": \"수상\", \"word2\": \"개\"}\n",
    "]\n",
    "\n",
    "# 추출 작업 수행 및 결과 저장\n",
    "target_column = 11  # 추출할 열의 인덱스 (0부터 시작)\n",
    "column_name = df.columns[target_column]  # 추출할 열의 이름\n",
    "extracted_data = []\n",
    "for condition in conditions:\n",
    "    word1 = condition[\"word1\"]\n",
    "    word2 = condition[\"word2\"]\n",
    "    extracted_values = df[column_name].apply(lambda x: extract_string_with_words(str(x), conditions))\n",
    "    extracted_data.append(extracted_values)\n",
    "\n",
    "# 추출한 값들을 기존 데이터프레임에 새로운 열로 추가\n",
    "# for i, condition in enumerate(conditions):\n",
    "#     word1 = condition[\"word1\"]\n",
    "#     word2 = condition[\"word2\"]\n",
    "#     new_column_name = f\"{word1}_{word2}\"\n",
    "#     df[new_column_name] = extracted_data[i]\n",
    "new_column_name = \"스펙_핵심_추출\"\n",
    "df[new_column_name] = extracted_data[0]\n",
    "\n",
    "# 수정된 데이터프레임을 CSV 파일로 출력하여 저장\n",
    "output_csv_file = \"수만휘_전처리_내신&학교&스펙.csv\"\n",
    "df.to_csv(output_csv_file, index=False, encoding='utf-8-sig')\n",
    "print(\"출력 파일이 생성되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d46d69e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def count_words_in_csv(input_file, target_column_index, words):\n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    counts = []\n",
    "    for row in rows:\n",
    "        cell = row[target_column_index]\n",
    "        count = 0\n",
    "        for word in words:\n",
    "            count += cell.count(word)\n",
    "        counts.append(count)\n",
    "\n",
    "    output_file = os.path.splitext(os.path.basename(input_file))[0] + '_output.csv'\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for row, count in zip(rows, counts):\n",
    "            row.append(str(count))\n",
    "            writer.writerow(row)\n",
    "\n",
    "input_file = '수만휘_전처리_내신&학교&스펙.csv'\n",
    "target_column_index = 11\n",
    "words = ['동아리', '상장', '수상', '독서', '봉사', '반장', '회장', '자소서', '학생회', '생기부', '세특', '임원', '프로젝트', '활동', '원서']\n",
    "\n",
    "count_words_in_csv(input_file, target_column_index, words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82103776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement summarize (from versions: none)\n",
      "ERROR: No matching distribution found for summarize\n"
     ]
    }
   ],
   "source": [
    "!pip install summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17818d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: summa in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: scipy>=0.19 in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (from summa) (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (from scipy>=0.19->summa) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7a603e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement summa.summarizer (from versions: none)\n",
      "ERROR: No matching distribution found for summa.summarizer\n"
     ]
    }
   ],
   "source": [
    "!pip install summa.summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fa63b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from summa.summarizer import summarize\n",
    "\n",
    "df = pd.read_csv('수만휘_전처리_내신&학교&스펙_output.csv', encoding='utf-8-sig')\n",
    "\n",
    "# 열 이름 변경\n",
    "df = df.rename(columns={'0': '중요단어 카운팅 수'})\n",
    "\n",
    "# 텍스트 요약\n",
    "summary = []\n",
    "for text in df['4. 스펙']:\n",
    "    if isinstance(text, str):  # 문자열인지 확인\n",
    "        words = text.split()  # 단어를 공백 기준으로 분리\n",
    "        num_words = len(words)\n",
    "        if num_words >= 20:  # 20단어 이상인 경우 요약 진행\n",
    "            summarized_text = summarize(text, words=30)  # 30단어로 요약\n",
    "            summarized_text = summarized_text.replace('\\n', ' ').replace('/', ' ')\n",
    "        else:\n",
    "            summarized_text = text.replace('\\n', ' ').replace('/', ' ')  # 20단어 이하인 경우 원문 그대로 출력\n",
    "    else:\n",
    "        summarized_text = ''  # 빈 데이터나 문자열이 아닌 경우 처리\n",
    "\n",
    "    summary.append(summarized_text)\n",
    "\n",
    "# 요약 결과를 새로운 열로 추가\n",
    "df['4. 요약'] = summary\n",
    "\n",
    "df.to_csv('수만휘_전처리_내신&학교&스펙&요약.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd76ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from summa.summarizer import summarize\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('수만휘_전처리_내신&학교&스펙&요약.csv', encoding='utf-8-sig')\n",
    "\n",
    "# '5. 후배들에게 전하고 싶은 말' 열의 텍스트 요약\n",
    "summary = []\n",
    "for text in df['5. 후배들에게 전하고 싶은 말']:\n",
    "    if isinstance(text, str):  # Check if the text is a string\n",
    "        words = text.split()  # 단어를 공백 기준으로 분리\n",
    "        num_words = len(words)\n",
    "        if num_words >= 20:  # 20단어 이상인 경우 요약 진행\n",
    "            summarized_text = summarize(text, words=20)  # 20단어로 요약\n",
    "            summarized_text = summarized_text.replace('\\n', ' ').replace('/', ' ')\n",
    "        else:\n",
    "            summarized_text = text.replace('\\n', ' ').replace('/', ' ')  # 20단어 이하인 경우 원문 그대로 출력\n",
    "    else:\n",
    "        summarized_text = ''  # Handle empty or non-string data\n",
    "\n",
    "    summary.append(summarized_text)\n",
    "\n",
    "# 요약 결과를 새로운 열로 추가\n",
    "df['5. 요약'] = summary\n",
    "\n",
    "df.to_csv('수만휘_전처리_내신&학교&스펙&요약.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f83db3",
   "metadata": {},
   "source": [
    "여기까지는 맨 처음 각자 전 처리 한 코드 합친 거."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbad9b7",
   "metadata": {},
   "source": [
    "[NEW]대학 분류 코드. 열을 여러개 생성하는 게 아니라, row를 복사해서 나머진 똑같고 '입시결과' 열의 내용만 달라지게 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f44963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 줄넘김으로 대학 분류하는 코드. 기존 열 추가 코드에서 행 복사->입시결과 열 값만 다르게 넣는 걸로 수정함.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "data = pd.read_csv('수만휘_전처리_내신&학교&스펙&요약.csv')\n",
    "\n",
    "# \"1. 입시결과 요약\" 열에서 텍스트 끊어서 \"new_col\"에 저장\n",
    "results = []\n",
    "summary_column = data['1. 입시결과 요약']\n",
    "for text in summary_column:\n",
    "    if pd.notnull(text):  # NaN 값이 아닌 경우에만 처리\n",
    "        # 대나 대학교가 포함된 단어 앞에서 줄넘김 처리\n",
    "        lines = []\n",
    "        current_line = ''\n",
    "        for word in text.split():\n",
    "            if '대' in word or '대학교' in word:\n",
    "                if current_line:\n",
    "                    lines.append(current_line)\n",
    "                current_line = word\n",
    "            else:\n",
    "                current_line += ' ' + word\n",
    "        if current_line:\n",
    "            lines.append(current_line)\n",
    "        formatted_text = '\\n'.join(lines)\n",
    "        # 맨 마지막 줄에 줄넘김 추가\n",
    "        if formatted_text:\n",
    "            formatted_text += '\\n'\n",
    "        results.append(formatted_text)\n",
    "    else:\n",
    "        results.append('')  # 결측치인 경우 빈 문자열로 처리\n",
    "\n",
    "# \"new_col\" 열을 DataFrame에 추가\n",
    "data['new_col'] = results\n",
    "\n",
    "# 'new_col'열이 결측치인 경우, 해당 row 제거\n",
    "data = data[data['new_col'] != '']\n",
    "\n",
    "# 새로운 칼럼 생성\n",
    "max_columns = 10  # 최대 칼럼 개수 제한\n",
    "num_lines = data['new_col'].str.count('\\n')  # 줄넘김 개수\n",
    "num_lines[num_lines > max_columns] = max_columns  # 최대 칼럼 개수 제한\n",
    "new_columns = [f\"입시결과{i+1}\" for i in range(max_columns)]  # 칼럼 이름 생성\n",
    "\n",
    "# 값 저장\n",
    "new_data = pd.DataFrame()\n",
    "for i, row in data.iterrows():\n",
    "    for j in range(max_columns):\n",
    "        new_row = row.copy()\n",
    "        if j < num_lines[i]:\n",
    "            new_row['입시결과'] = row['new_col'].split('\\n')[j]\n",
    "        else:\n",
    "            new_row['입시결과'] = ''\n",
    "        new_data = pd.concat([new_data, new_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "# '입시결과'열이 결측치인 경우, 해당 row 제거\n",
    "#new_data = new_data.dropna(subset=['입시결과'])\n",
    "# 결측치인 row 제거\n",
    "new_data = new_data[new_data['입시결과'] != '']\n",
    "\n",
    "# 새로운 CSV 파일로 저장\n",
    "new_data.to_csv('수만휘_전처리_내신&학교&스펙&요약&대학분류.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd0182c",
   "metadata": {},
   "source": [
    "[대학 나누기 + 단어 태깅까지 완료한 코드]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93f341c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv('수만휘_전처리_내신&학교&스펙&요약&대학분류.csv')\n",
    "\n",
    "# 태깅 결과를 저장할 리스트 초기화\n",
    "universities = []\n",
    "departments = []\n",
    "results = []\n",
    "\n",
    "# 각 텍스트에서 '대학교', '학과명', '합불여부' 태깅\n",
    "for text in df['입시결과']:\n",
    "    # 태깅 결과를 저장할 딕셔너리 초기화\n",
    "    tags = {\n",
    "        '대학명': None,\n",
    "        '학과명': None,\n",
    "        '합불여부': None\n",
    "    }\n",
    "\n",
    "    # '대학교' 태깅\n",
    "    match = re.search(r'\\b(\\w*대학\\w*|.*대)\\b', text)\n",
    "    if match:\n",
    "        tags['대학명'] = match.group()\n",
    "\n",
    "    # '학과명' 태깅\n",
    "    match = re.search(r'\\b(\\w*과\\w*|\\w*학과\\w*|\\w*학부\\w*)\\b', text)\n",
    "    if match:\n",
    "        department = match.group()\n",
    "        if '교과' not in department and '종합' not in department:\n",
    "            tags['학과명'] = department\n",
    "\n",
    "    # '합불여부' 태깅\n",
    "    match = re.search(r'\\b(\\w*합(?!.*[대학교|학과명])\\w*)|(\\w*탈(?!.*[대학교|학과명])\\w*)|(\\w*불(?!.*[대학교|학과명])\\w*)|(\\w*예(?!.*[대학교|학과명])\\w*)|(\\w*최(?!.*[대학교|학과명])\\w*)|(\\w*미(?!.*[대학교|학과명])\\w*)|(\\w*떨(?!.*[대학교|학과명])\\w*)\\b', text)\n",
    "    if match:\n",
    "        department = match.group()\n",
    "        if '종합' not in department:\n",
    "            tags['합불여부'] = department\n",
    "\n",
    "    # 태깅 결과를 리스트에 저장\n",
    "    universities.append(tags['대학명'])\n",
    "    departments.append(tags['학과명'])\n",
    "    results.append(tags['합불여부'])\n",
    "\n",
    "# 태깅 결과로 새로운 열을 추가한 데이터프레임 생성\n",
    "df['대학명'] = universities\n",
    "df['학과명'] = departments\n",
    "df['합불여부'] = results\n",
    "\n",
    "# 새로운 CSV 파일로 저장\n",
    "df.to_csv('수만휘_전처리_내신&학교&스펙&요약&대학분류&태깅.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3edb754",
   "metadata": {},
   "source": [
    "최종 검색 모델 만들기\n",
    "-현재 '대학명','학과명'치면 해당하는 row까지 검색 가능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb63214d",
   "metadata": {},
   "source": [
    "'광운대학교' 라고 검색하는 것보다 '광운'이라고 검색해야 더 잘 나옵니다. 해당 단어 포함하고 있는 row을 검색하게 만들었기 때문데, 광운대학교라고 치면 \"광운대학교\"라는 단어가 그대로 박힌 row밖에 안 뽑아줘요. \n",
    "다른 학교로 생각하셔도 똑같아요. 고려대 검색하려면 \"고려/경영\" 또는 \"고려/경영학과\" 이런 식으로 검색하시는 게 좋아용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3b514a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치 개수: 5890\n",
      "전체 row 개수: 14919\n",
      "Index(['no', 'title', 'link', 'name', 'date', 'view', 'content', 'idx_no',\n",
      "       '1. 입시결과 요약', '2. 출신고교 종류', '3. 내신/수능점수', '4. 스펙', '5. 후배들에게 전하고 싶은 말',\n",
      "       '스펙_핵심_추출', '중요단어 카운팅 수', '4. 요약', '5. 요약', 'new_col', '입시결과', '대학명',\n",
      "       '학과명', '합불여부'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 결측치 확인하는 코드\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # CSV 파일 불러오기\n",
    "# data = pd.read_csv('수만휘_전처리_내신&학교&스펙&대학분류&태깅.csv')\n",
    "# 원하는 col 결측치 보기\n",
    "missing_values = df['학과명'].isnull().sum()\n",
    "print(f\"결측치 개수: {missing_values}\")\n",
    "# 전체 col 갯수 보기\n",
    "total_rows = len(df)\n",
    "print(f\"전체 row 개수: {total_rows}\")\n",
    "\n",
    "#칼럼 Name 출력\n",
    "column_names = df.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee6469d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dlxod\\Textmining_코드통합.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dlxod/Textmining_%EC%BD%94%EB%93%9C%ED%86%B5%ED%95%A9.ipynb#X65sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(filtered_df[\u001b[39m'\u001b[39m\u001b[39m3. 내신/수능점수\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filtered_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(filtered_df['3. 내신/수능점수'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b02e509a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Selenium in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (4.9.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (from Selenium) (0.10.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (from Selenium) (0.22.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (from Selenium) (2023.5.7)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (from Selenium) (1.26.15)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (from trio~=0.17->Selenium) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (from trio~=0.17->Selenium) (1.1.1)\n",
      "Requirement already satisfied: outcome in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (from trio~=0.17->Selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (from trio~=0.17->Selenium) (1.3.0)\n",
      "Requirement already satisfied: idna in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (from trio~=0.17->Selenium) (3.4)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (from trio~=0.17->Selenium) (1.15.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (from trio~=0.17->Selenium) (22.1.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (from trio~=0.17->Selenium) (1.10)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->Selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->Selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->Selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\dlxod\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->Selenium) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n",
      "'apt'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n"
     ]
    }
   ],
   "source": [
    "!pip install Selenium\n",
    "!apt-get update \n",
    "!apt install chromium-chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d2e0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\users\\dlxod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\dlxod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from konlpy) (4.9.2)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\dlxod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from konlpy) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\dlxod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from konlpy) (1.24.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\dlxod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\dlxod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dlxod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dlxod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dlxod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dlxod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dlxod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dlxod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install konlpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da17331e",
   "metadata": {},
   "source": [
    "★★★검색 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e52f03d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:134: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:134: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원하시는 대학명과 학과를 입력해주세요 ex)광운/정보융합 : 광운/정보융합\n",
      "태깅된 행을 찾았습니다. 해당하는 열의 개수: 8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlxod\\AppData\\Local\\Temp\\ipykernel_19324\\980398444.py:89: DeprecationWarning: use options instead of chrome_options\n",
      "  wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
      "C:\\Users\\dlxod\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\konlpy\\tag\\_okt.py:17: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n",
      "C:\\Users\\dlxod\\AppData\\Local\\Temp\\ipykernel_19324\\980398444.py:134: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if sentence is not '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
      "[광운/정보융합에 게시글들에 대한 통합 결과입니다]\n",
      "광운/정보융합의 합격 수기를 작성한 이들의 내신 평균 점수:3.33\n",
      "광운/정보융합의 합격 수기를 작성한 이들의 고등학교 유형 분류 결과: \n",
      "일반고: 7개 (87.50%)\n",
      "자사고: 0개 (0.00%)\n",
      "특성화고: 0개 (0.00%)\n",
      "과학고: 0개 (0.00%)\n",
      "외고: 0개 (0.00%)\n",
      "광운/정보융합 사람들의 스펙 핵심 키워드 : \n",
      "['기부', '대회', '파이썬', '코딩', '동아리', '학습', '컴퓨터', '봉사', '전공', '관련']\n",
      "ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
      "\n",
      "[광운/정보융합에 대한 1번째 게시글입니다.]\n",
      "1. 글 제목: <광운대 정보융합 최초합 기록>\n",
      "2. 작성 날짜: 2022.11.11.\n",
      "3. 출신 고교: 일반고\n",
      "4. 내신 점수: nan\n",
      "5. 입시 결과: \n",
      "광운대/정보융합학부/소프트웨어우수전형\n",
      "6. 스펙 핵심: []\n",
      "6. 스펙 요약:   많아서 다 적지는 못하겠지만.. 123학년 생기부 대부분이 컴퓨터관련 활동으로 채워져있음 프로그래밍 프로젝트 10개 이상  \n",
      "7. 후배들에게 전하고 싶은 말: 면접 얘기를 조금 하면 소프트웨어우수자전형이 활동 많이 물어볼줄 알았는데 면접때 활동 하나도 안물어봄. 시간이 되면 면접 내용 자세하게 글 적어둘게요 \n",
      "\n",
      "ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
      "\n",
      "[광운/정보융합에 대한 2번째 게시글입니다.]\n",
      "1. 글 제목: <일반고 3.1 4합 수시 최종 기록 (최대한 자세하게 적었어요!)>\n",
      "2. 작성 날짜: 2022.07.07.\n",
      "3. 출신 고교: 일반고\n",
      "4. 내신 점수: nan\n",
      "5. 입시 결과: \n",
      "동국대학교 고른기회통합농어촌전형 AI 융합학부 - 1차 불합\n",
      "서울과학기술대학교 첨단인재전형 인공지능응용학과 - 1차 불합\n",
      "국민대학교 학생부종합농어촌전형 소프트웨어학부 - 예비 5번 2차 추합\n",
      "세종대학교 학생부종합고른기회 인공지능학과 - 최초합\n",
      "광운대학교 학생부종합농어촌전형 정보융합학부 - 최초합\n",
      "가천대학교 학생부종합농어촌전형 인공지능전공 - 최초합\n",
      "6. 스펙 핵심: ['생기부 18장']\n",
      "6. 스펙 요약: nan\n",
      "7. 후배들에게 전하고 싶은 말: 세특은 이런 식으로 진행하고 창체는 제가 프로젝트를 진행해서 결과물이 나올 수 있도록 노력한 것 같아요 입시 끝나고 생각해보면 교과 선생님들께 뜬금없이 가서 보고서 제출하고 생기부 관련해서 부탁도 많이 드리고...\n",
      "\n",
      "ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
      "\n",
      "[광운/정보융합에 대한 3번째 게시글입니다.]\n",
      "1. 글 제목: <평준 일반고 2.8의 학종 리뷰>\n",
      "2. 작성 날짜: 2022.01.03.\n",
      "3. 출신 고교: 일반고\n",
      "4. 내신 점수: nan\n",
      "5. 입시 결과: \n",
      "경희대 소프트웨어융합학과 네오르네상스-2차 추합 등록5-1\n",
      "국민대 소프트웨어학과 국민프런티어 -최초합\n",
      "인하대 컴퓨터공학과 인하참인재 -최초합\n",
      "광운대 정보융합학부 광운참빛인재 -최초합\n",
      "세종대 컴퓨터공학과 창의인재전형 -우주예비 불합\n",
      "부산대 정보컴퓨터공학부 학생부교과지역인재 -우주예비 불합\n",
      "6. 스펙 핵심: ['생기부 17장']\n",
      "6. 스펙 요약: 생기부 17장  2년 컴퓨터관련 동아리 하면서 개인 프로젝트로 간단한 게임이나 파이썬을 이용해서 데이터 클러스터링 프로젝트를 했습니다. 인공지능과 데이터 분석에 관심을 보였고 이에 관한 만들고 싶은 프로그램을 자소서와 면접에서 어필하면서 제가 이 학과에 가야만 하는 이유를 만들었습니다.\n",
      "7. 후배들에게 전하고 싶은 말:   학종 열심히 챙겨 두시면 후회 안 할 것 같습니다.   \n",
      "\n",
      "ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 여기가 \"학교명/학과명\"으로 검색하는 기능 구현 코드\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv('수만휘_전처리_내신&학교&스펙&요약&대학분류&태깅.csv')\n",
    "\n",
    "# 사용자 입력 받기\n",
    "user_input = input(\"원하시는 대학명과 학과를 입력해주세요 ex)광운/정보융합 : \")\n",
    "\n",
    "# 대학명과 학과명 추출\n",
    "match = re.search(r'(\\w+)/(\\w+)', user_input)\n",
    "if match:\n",
    "    university = match.group(1)\n",
    "    department = match.group(2)\n",
    "else:\n",
    "    print(\"입력이 올바르지 않습니다.\")\n",
    "    exit()\n",
    "\n",
    "# 대학명과 학과명이 포함된 행 찾기\n",
    "filtered_df = df[df['대학명'].str.contains(university) & df['학과명'].str.contains(department)]\n",
    "\n",
    "# 결과 출력\n",
    "if len(filtered_df) > 0:\n",
    "    print(\"태깅된 행을 찾았습니다. 해당하는 열의 개수:\", len(filtered_df))\n",
    "    print(\"\")\n",
    "else:\n",
    "    print(\"일치하는 태깅된 행이 없습니다.\")\n",
    "\n",
    "##########################################################################################################\n",
    "# 여기부터 희원이 키워드 추출 코드\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "import re\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Twitter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv('수만휘_전처리_내신&학교&스펙&대학분류&태깅.csv', encoding='utf-8-sig')\n",
    "\n",
    "filtered_df.loc[:, '4. 스펙'] = filtered_df['4. 스펙'].fillna('').apply(lambda x: re.sub('[^가-힣0-9\\s]', '', x))\n",
    "\n",
    "# '4. 스펙' 열의 내용을 하나의 문자열로 합치기\n",
    "spec_string = ' '.join(filtered_df['4. 스펙'].astype(str).tolist())\n",
    "\n",
    "# 형태소 분석기 초기화\n",
    "okt = Okt()\n",
    "# 형태소 분석 수행\n",
    "morphs = okt.nouns(spec_string)\n",
    "# 단어 카운트\n",
    "word_counter = Counter(morphs)\n",
    "\n",
    "# 가장 많이 나온 상위 10개의 단어 추출\n",
    "top_10_words = word_counter.most_common(10)\n",
    "top_10_words = [word[0] for word in top_10_words]\n",
    "# 상위 10개 단어\n",
    "sentence = ' '.join(top_10_words)\n",
    "\n",
    "#입력한 단어 리스트(words)에 해당하는 문장들을 filtered_df의 '4. 스펙' 열에서 추출하는 작업을 수행\n",
    "# 입력한 단어 리스트\n",
    "words = ['동아리', '상장', '수상', '봉사', '반장', '회장', '자소서', '학생회', '세특', '임원', '프로젝트', '활동', '원서', '상', '대회', '부장', '확장', '활동', '발표', '주제', '분야', '수상경력', '보고서']\n",
    "\n",
    "# 단어 리스트에 해당하는 문장 추출\n",
    "selected_sentences = []\n",
    "for sentence in filtered_df['4. 스펙']:\n",
    "    if any(word in sentence for word in words):\n",
    "        sentence = sentence.replace('\\n', '.').replace('  ', ' ')\n",
    "        selected_sentences.append(sentence)\n",
    "        \n",
    "sentences = selected_sentences\n",
    "# 문장들을 담은 리스트로부터 데이터프레임 생성\n",
    "spec_data = pd.DataFrame({'Sentences': sentences})\n",
    "\n",
    "# 부산대 맞춤법 검사기 - 1차 교정\n",
    "# 브라우저 주소를 통해 \"부산대 맞춤법 교정기\" 페이지로 이동해서 교정을 시행한 후, 교정된 텍스트을 가져오는 코드\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
    "def spell_checking(sentence, text_list):\n",
    "    for i in (range(len(sentence))):\n",
    "        time.sleep(0.5)\n",
    "        wd.get('http://speller.cs.pusan.ac.kr/')\n",
    "        try:\n",
    "            wd.find_element_by_xpath('//*[@id=\"text1\"]').send_keys(sentence[i])\n",
    "            wd.find_element_by_xpath('//*[@id=\"btnCheck\"]').click()\n",
    "            time.sleep(1)\n",
    "            entity_num = 0\n",
    "            while True:\n",
    "                try:\n",
    "                    wd.find_element_by_xpath('//*[@id=\"tdReplaceWord_'+str(entity_num)+'\"]/ul/li/a').click()\n",
    "                    entity_num += 1\n",
    "                except:\n",
    "                    break\n",
    "            texts = wd.find_element_by_xpath('//*[@id=\"tdCorrection1stBox\"]').text\n",
    "            text_list.append(texts)\n",
    "        except:\n",
    "            text_list.append(sentence[i])\n",
    "\n",
    "test_spell_list = []\n",
    "\n",
    "spell_checking(spec_data['Sentences'], test_spell_list)\n",
    "\n",
    "# 문장을 문장단위로 나누는 함수\n",
    "# test_spell_list에는 맞춤법 교정이 적용된 문장들이 저장되어 있음\n",
    "def split_sentences(text):\n",
    "    sentences = text.split('.')\n",
    "    cleaned_sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "    return cleaned_sentences\n",
    "\n",
    "# 문장별로 나누기\n",
    "sentences = []\n",
    "for text in test_spell_list:\n",
    "    sentences.extend(split_sentences(text))\n",
    "    \n",
    "twitter = Twitter()\n",
    "\n",
    "#불용어제거\n",
    "stopwords = ['학년' , \"때\", \"개\", \"권\", \"시간\", \"나\", \"우리\", \"저희\", \"따라\", \"의해\", \"을\", \"를\", \"에\", \"의\", \"가\", \"장\"]\n",
    "\n",
    "def get_nouns(sentences):\n",
    "    nouns = []\n",
    "    for sentence in sentences:\n",
    "        if sentence is not '':\n",
    "            nouns.append(' '.join([noun for noun in twitter.nouns(str(sentence))\n",
    "                                  if noun not in stopwords and len(noun) > 1]))\n",
    "    return nouns\n",
    "\n",
    "nouns = get_nouns(sentences)\n",
    "\n",
    "# TF-IDF 모델 생성 및 그래프 생성\n",
    "tfidf = TfidfVectorizer()\n",
    "cnt_vec = CountVectorizer()\n",
    "graph_sentence = []\n",
    "\n",
    "def build_sent_graph(sentence):\n",
    "    tfidf_mat = tfidf.fit_transform(sentence).toarray()\n",
    "    graph_sentence = np.dot(tfidf_mat, tfidf_mat.T)\n",
    "    return graph_sentence\n",
    "\n",
    "sent_graph = build_sent_graph(nouns)\n",
    "\n",
    "def build_words_graph(sentence):\n",
    "    cnt_vec_mat = normalize(cnt_vec.fit_transform(sentence).toarray().astype(float), axis=0)\n",
    "    vocab = cnt_vec.vocabulary_\n",
    "    return np.dot(cnt_vec_mat.T, cnt_vec_mat), {vocab[word] : word for word in vocab}\n",
    "\n",
    "words_graph, idx2word = build_words_graph(nouns)\n",
    "\n",
    "# TextRank 구현\n",
    "# 각 단어의 중요도를 계산하여 반환\n",
    "def get_ranks(graph, d=0.85): # d = damping factor\n",
    "    A = graph\n",
    "    matrix_size = A.shape[0]\n",
    "    for id in range(matrix_size):\n",
    "        A[id, id] = 0 # diagonal 부분을 0으로\n",
    "        link_sum = np.sum(A[:,id]) # A[:, id] = A[:][id]\n",
    "        if link_sum != 0:\n",
    "            A[:, id] /= link_sum\n",
    "        A[:, id] *= -d\n",
    "        A[id, id] = 1\n",
    "\n",
    "    B = (1-d) * np.ones((matrix_size, 1))\n",
    "    ranks = np.linalg.solve(A, B) # 연립방정식 Ax = b\n",
    "    return {idx: r[0] for idx, r in enumerate(ranks)}\n",
    "\n",
    "sent_rank_idx = get_ranks(sent_graph)  #sent_graph : sentence 가중치 그래프\n",
    "\n",
    "sorted_sent_rank_idx = sorted(sent_rank_idx, key=lambda k: sent_rank_idx[k], reverse=True)\n",
    "\n",
    "#앞에 있는 인덱스의 문장일수록 점수가 가장 높게 매겨졌음을 나타냄.\n",
    "word_rank_idx = get_ranks(words_graph)\n",
    "sorted_word_rank_idx = sorted(word_rank_idx, key=lambda k: word_rank_idx[k], reverse=True)\n",
    "\n",
    "def summarize(sent_num=5):\n",
    "    summary = []\n",
    "    index = []\n",
    "    for idx in sorted_sent_rank_idx[:sent_num].copy():\n",
    "        index.append(idx)\n",
    "\n",
    "    index.sort()\n",
    "\n",
    "    for idx in index:\n",
    "        summary.append(sentences[idx])\n",
    "\n",
    "    return summary\n",
    "\n",
    "def find_no_values(summaries, df):\n",
    "    no_values = []\n",
    "    for summary in summaries:\n",
    "        found = False  # 요약문이 발견되었는지 여부를 나타내는 변수\n",
    "        for index, row in df.iterrows():\n",
    "            if summary in row['4. 스펙']:\n",
    "                no_values.append(row['no'])\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            no_values.append(None)  # 요약문이 발견되지 않은 경우 None 값을 추가\n",
    "    return no_values\n",
    "\n",
    "\n",
    "# summarize() 함수를 사용하여 요약문 생성\n",
    "# summaries = summarize()\n",
    "\n",
    "# 요약문과 해당하는 \"no\" 값을 출력\n",
    "# no_values = find_no_values(summaries, filtered_df)\n",
    "# for i in range(len(summaries)):\n",
    "#     print(\"요약문:\", summaries[i])\n",
    "#     print(\"해당하는 'no' 값:\", no_values[i])\n",
    "#     print()\n",
    "# summarize() 함수를 사용하여 요약문 생성\n",
    "summaries = summarize()\n",
    "\n",
    "# 요약문과 해당하는 \"no\" 값을 출력하지 않음\n",
    "no_values = find_no_values(summaries, filtered_df)\n",
    "for i in range(len(summaries)):\n",
    "    pass\n",
    "\n",
    "def keywords(word_num=10):\n",
    "    keywords = []\n",
    "    index=[]\n",
    "    for idx in sorted_word_rank_idx[:word_num]:\n",
    "        index.append(idx)\n",
    "\n",
    "    #index.sort()\n",
    "    for idx in index:\n",
    "        keywords.append(idx2word[idx])\n",
    "\n",
    "    print(f\"{user_input} 사람들의 스펙 핵심 키워드 : \")\n",
    "    print(keywords)\n",
    "# keywords()\n",
    "\n",
    "##########################################################################################################\n",
    "# 이건 지원이가 짠 3. 내신/수능 점수 열에서 평균 구하는 코드\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# 숫자 값 추출 함수 정의\n",
    "def extract_number(value):\n",
    "    try:\n",
    "        number = re.findall(r'[+-]?\\d+(?:\\.\\d+)?', str(value))\n",
    "        if len(number) > 0:\n",
    "            return float(number[0])\n",
    "        else:\n",
    "            return np.nan\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "# 각 셀에 있는 숫자 값 추출하여 리스트에 저장\n",
    "numbers = []\n",
    "for value in filtered_df['3. 내신/수능점수']:\n",
    "    number = extract_number(value)\n",
    "    if not np.isnan(number):\n",
    "        numbers.append(number)\n",
    "\n",
    "# 평균 계산\n",
    "average = np.mean(numbers)\n",
    "\n",
    "# 평균 값을 소수점 둘째 자리에서 반올림하여 출력\n",
    "# rounded_average 변수에 검색한 학교/학과 사람들의 평균 내신 점수 넣음.\n",
    "rounded_average = round(average, 2)\n",
    "# print(\"평균:\", rounded_average)\n",
    "\n",
    "# 여기서부터는 filtered_df에 대한 고등학교 비율 계산 코드\n",
    "import pandas as pd\n",
    "\n",
    "# filtered_df 데이터프레임에서 학교 유형 분류 및 카운트\n",
    "school_types = ['일반고', '자사고', '특성화고', '과학고', '외고']\n",
    "total_count = len(filtered_df)\n",
    "type_counts = filtered_df['2. 출신고교 종류'].value_counts()\n",
    "\n",
    "# '외고'와 '외국어고'를 하나로 합치기\n",
    "type_counts['외고'] = type_counts.get('외고', 0) + type_counts.get('외국어고', 0)\n",
    "if '외국어고' in type_counts:\n",
    "    del type_counts['외국어고']\n",
    "\n",
    "##########################################################################################################\n",
    "# 검색 결과 출력 창\n",
    "# '중요단어 카운팅 수'기반 [결과 출력 창]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# '중요단어 카운팅 수'에 대한 구간 설정\n",
    "bins = np.arange(0, filtered_df['중요단어 카운팅 수'].max() + 6, 5)\n",
    "# 구간별로 치환된 값을 새로운 열에 저장\n",
    "filtered_df['가중치_중요단어카운팅수'] = pd.cut(filtered_df['중요단어 카운팅 수'], bins, labels=False) + 1\n",
    "\n",
    "# 'view' 열의 값을 숫자형으로 변환\n",
    "filtered_df['view'] = pd.to_numeric(filtered_df['view'], errors='coerce')\n",
    "\n",
    "# '3. 내신/수능점수' 열의 값을 숫자형으로 변환\n",
    "filtered_df['3. 내신/수능점수'] = pd.to_numeric(filtered_df['3. 내신/수능점수'], errors='coerce')\n",
    "\n",
    "# 'view' 열의 값을 50으로 나눈 뒤 올림하여 1로 치환\n",
    "filtered_df['가중치_조회수'] = np.ceil(filtered_df['view'] / 50)\n",
    "\n",
    "# 'rounded_average'와 '3. 내신/수능점수' 열의 차이 계산\n",
    "filtered_df['가중치_성적'] = filtered_df['3. 내신/수능점수'].apply(pd.to_numeric, errors='coerce')\n",
    "filtered_df['가중치_성적'] = abs(filtered_df['가중치_성적'] - rounded_average)\n",
    "\n",
    "\n",
    "# 1, 2, 3 열 값을 더하여 새로운 열 생성\n",
    "filtered_df['합계'] = filtered_df['가중치_중요단어카운팅수'] + filtered_df['가중치_조회수'] \n",
    "#+ filtered_df['가중치_성적']\n",
    "\n",
    "# 중요단어 카운팅 수와 no 열을 기준으로 중복 제거\n",
    "filtered_df = filtered_df.sort_values(by=['합계'], ascending=False)\n",
    "filtered_df = filtered_df.drop_duplicates(subset=['합계', 'no'], keep='first')\n",
    "\n",
    "\n",
    "\n",
    "print(\"ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\")\n",
    "print(f\"[{user_input}에 게시글들에 대한 통합 결과입니다]\")\n",
    "print(f\"{user_input}의 합격 수기를 작성한 이들의 내신 평균 점수:\"+str(rounded_average))\n",
    "print(f\"{user_input}의 합격 수기를 작성한 이들의 고등학교 유형 분류 결과: \")\n",
    "for school_type in school_types:\n",
    "    count = type_counts.get(school_type, 0)\n",
    "    percentage = (count / total_count) * 100\n",
    "    print(f'{school_type}: {count}개 ({percentage:.2f}%)')\n",
    "keywords()\n",
    "\n",
    "print(\"ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\")\n",
    "print(\"\")\n",
    "for i, row in enumerate(filtered_df.head(3).iterrows(), start=1):\n",
    "    print(f\"[{user_input}에 대한 {i}번째 게시글입니다.]\")\n",
    "    print(f\"1. 글 제목: <{row[1]['title']}>\")\n",
    "    print(f\"2. 작성 날짜: {row[1]['date']}\")\n",
    "    print(f\"3. 출신 고교: {row[1]['2. 출신고교 종류']}\")\n",
    "    print(f\"4. 내신 점수: {row[1]['3. 내신/수능점수']}\")\n",
    "    print(f\"5. 입시 결과: \\n{row[1]['new_col']}\",end=\"\")\n",
    "    print(f\"6. 스펙 핵심: {row[1]['스펙_핵심_추출']}\")\n",
    "    print(f\"6. 스펙 요약: {row[1]['4. 요약']}\")\n",
    "    print(f\"7. 후배들에게 전하고 싶은 말: {row[1]['5. 요약']}\")\n",
    "    print(\"\")\n",
    "    print(\"ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc81b443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★광운/정보융합 사람들의 스펙 핵심 키워드 : \n",
      "['기부', '대회', '파이썬', '코딩', '동아리', '학습', '컴퓨터', '봉사', '전공', '관련']\n",
      "ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
      "\n",
      "[광운/정보융합에 대한 1번째 게시글입니다.]\n",
      "1. 글 제목: <일반고 3.1 4합 수시 최종 기록 (최대한 자세하게 적었어요!)>\n",
      "2. 작성 날짜: .07.07.\n",
      "3. 출신 고교: 일반고\n",
      "4. 내신 점수: nan\n",
      "5. 입시 결과: \n",
      "동국대학교 고른기회통합농어촌전형 AI 융합학부 - 1차 불합\n",
      "서울과학기술대학교 첨단인재전형 인공지능응용학과 - 1차 불합\n",
      "국민대학교 학생부종합농어촌전형 소프트웨어학부 - 예비 5번 2차 추합\n",
      "세종대학교 학생부종합고른기회 인공지능학과 - 최초합\n",
      "광운대학교 학생부종합농어촌전형 정보융합학부 - 최초합\n",
      "가천대학교 학생부종합농어촌전형 인공지능전공 - 최초합\n",
      "6. 스펙 핵심: ['생기부 18장']\n",
      "6. 스펙 요약: nan\n",
      "7. 후배들에게 전하고 싶은 말: 세특은 이런 식으로 진행하고 창체는 제가 프로젝트를 진행해서 결과물이 나올 수 있도록 노력한 것 같아요 입시 끝나고 생각해보면 교과 선생님들께 뜬금없이 가서 보고서 제출하고 생기부 관련해서 부탁도 많이 드리고...\n",
      "\n",
      "ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
      "\n",
      "[광운/정보융합에 대한 2번째 게시글입니다.]\n",
      "1. 글 제목: <일반고 4.5 광운대 정보융합학부 최초합>\n",
      "2. 작성 날짜: .11.12.\n",
      "3. 출신 고교: 일반고\n",
      "4. 내신 점수: 4.5\n",
      "5. 입시 결과: \n",
      "광운대학교 / 정보융합학부 / 소프트웨어우수인재전형\n",
      "6. 스펙 핵심: ['생기부 18장', '봉사 시간']\n",
      "6. 스펙 요약: nan\n",
      "7. 후배들에게 전하고 싶은 말: nan\n",
      "\n",
      "ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
      "\n",
      "[광운/정보융합에 대한 3번째 게시글입니다.]\n",
      "1. 글 제목: <경기권 이과 내신 3.09 국민대 장학금>\n",
      "2. 작성 날짜: .12.24.\n",
      "3. 출신 고교: 일반고\n",
      "4. 내신 점수: 3.51\n",
      "5. 입시 결과: \n",
      "국민대학교/미래모빌리티학과/국민프런티어전형- 최초합2년동안 입학 성적 우수 장학금\n",
      "인하대학교/스마트모빌리티공학과/인하미래인재전형- 추합예비3번 1차 추합\n",
      "항공대학교/ai자율주행시스템공학과/미래인재전형- 불합격예비 9번\n",
      "광운대학교/정보융합학부/광운참빛인재전형- 1차 불합\n",
      "인천대학교/정보통신공학과/교과성적우수자전형- 예비 28번\n",
      "한국산업기술대학교한국공대/소프트웨어학과/교과성적우수자전형- 최초합\n",
      "6. 스펙 핵심: ['봉사시간 시간']\n",
      "6. 스펙 요약: - 경기 꿈의 대학 파이썬 강의 - 자율주행 자동차 파이썬 개발 - 자율주행 비행기 VR 게임 개발 - 4차 산업혁명 강의 - IoT 관련 발표 - 인공지능 관련 책 읽고 발표  3학년 때는 진로를 더 깊게 잡아 자율주행 분야로 결정하고 탐구하였습니다.\n",
      "7. 후배들에게 전하고 싶은 말: 그 다음 2학년 때부터 제대로 진로를 정하시고 열심히 활동해서 생기부 채우시고 3학년 때 더 깊이 탐구하신다면 좋은 결과로 나올 수 있을 것 같아요.\n",
      "\n",
      "ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# '중요단어 카운팅 수'기반 [결과 출력 창]\n",
    "import pandas as pd\n",
    "\n",
    "# 중요단어 카운팅 수와 no 열을 기준으로 중복 제거\n",
    "filtered_df = filtered_df.sort_values(by=['중요단어 카운팅 수', 'no'], ascending=False)\n",
    "filtered_df = filtered_df.drop_duplicates(subset=['중요단어 카운팅 수', 'no'], keep='first')\n",
    "\n",
    "print(f\"[{user_input}에 게시글들에 대한 통합 결과입니다]\")\n",
    "print(f\"{user_input}의 합격 수기를 작성한 이들의 내신 평균 점수:\"+rounded_average)\n",
    "print(f\"{user_input}의 합격 수기를 작성한 이들의 고등학교 유형 분류 결과: \")\n",
    "for school_type in school_types:\n",
    "    count = type_counts.get(school_type, 0)\n",
    "    percentage = (count / total_count) * 100\n",
    "    print(f'{school_type}: {count}개 ({percentage:.2f}%)')\n",
    "keywords()\n",
    "\n",
    "print(\"ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\")\n",
    "print(\"\")\n",
    "for i, row in enumerate(filtered_df.head(3).iterrows(), start=1):\n",
    "    print(f\"[{user_input}에 대한 {i}번째 게시글입니다.]\")\n",
    "    print(f\"1. 글 제목: <{row[1]['title']}>\")\n",
    "    print(f\"2. 작성 날짜: {row[1]['date']}\")\n",
    "    print(f\"3. 출신 고교: {row[1]['2. 출신고교 종류']}\")\n",
    "    print(f\"4. 내신 점수: {row[1]['3. 내신/수능점수']}\")\n",
    "    print(f\"5. 입시 결과: \\n{row[1]['new_col']}\",end=\"\")\n",
    "    print(f\"6. 스펙 핵심: {row[1]['스펙_핵심_추출']}\")\n",
    "    print(f\"6. 스펙 요약: {row[1]['4. 요약']}\")\n",
    "    print(f\"7. 후배들에게 전하고 싶은 말: {row[1]['5. 요약']}\")\n",
    "    print(\"\")\n",
    "    print(\"ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8036d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균: 3.33\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# 숫자 값 추출 함수 정의\n",
    "def extract_number(value):\n",
    "    try:\n",
    "        number = re.findall(r'[+-]?\\d+(?:\\.\\d+)?', str(value))\n",
    "        if len(number) > 0:\n",
    "            return float(number[0])\n",
    "        else:\n",
    "            return np.nan\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "# 각 셀에 있는 숫자 값 추출하여 리스트에 저장\n",
    "numbers = []\n",
    "for value in filtered_df['3. 내신/수능점수']:\n",
    "    number = extract_number(value)\n",
    "    if not np.isnan(number):\n",
    "        numbers.append(number)\n",
    "\n",
    "# 평균 계산\n",
    "average = np.mean(numbers)\n",
    "\n",
    "# 평균 값을 소수점 둘째 자리에서 반올림하여 출력\n",
    "# rounded_average 변수에 검색한 학교/학과 사람들의 평균 내신 점수 넣음.\n",
    "rounded_average = round(average, 2)\n",
    "print(\"평균:\", rounded_average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcc51b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학교 유형 분류 결과:\n",
      "일반고: 7개 (87.50%)\n",
      "자사고: 0개 (0.00%)\n",
      "특성화고: 0개 (0.00%)\n",
      "과학고: 0개 (0.00%)\n",
      "외고: 0개 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# filtered_df 데이터프레임에서 학교 유형 분류 및 카운트\n",
    "school_types = ['일반고', '자사고', '특성화고', '과학고', '외고']\n",
    "total_count = len(filtered_df)\n",
    "type_counts = filtered_df['2. 출신고교 종류'].value_counts()\n",
    "\n",
    "# '외고'와 '외국어고'를 하나로 합치기\n",
    "type_counts['외고'] = type_counts.get('외고', 0) + type_counts.get('외국어고', 0)\n",
    "if '외국어고' in type_counts:\n",
    "    del type_counts['외국어고']\n",
    "\n",
    "# 분류 결과 출력\n",
    "print('학교 유형 분류 결과:')\n",
    "for school_type in school_types:\n",
    "    count = type_counts.get(school_type, 0)\n",
    "    percentage = (count / total_count) * 100\n",
    "    print(f'{school_type}: {count}개 ({percentage:.2f}%)')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
